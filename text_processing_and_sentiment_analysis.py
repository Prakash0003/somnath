# -*- coding: utf-8 -*-
"""Text Processing and Sentiment Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N89B5OZ9D00Qrx5ecWK5C6kyvAclw4Yc
"""

from PIL import Image
img = Image.open('/content/e commerce.jpg')
img

#Performed text preprocessing
              #sentiment analysis on womenâ€™s clothing e-commerce reviews.
#Key Responsibilities:
      #Cleaned and normalized text data, corrected spelling errors, and lemmatized words.
      #Analyzed sentiment using VADER (Valence Aware Dictionary and sEntiment Reasoner)



# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('/content/Womens Clothing E-Commerce Reviews.csv')
data.head()

data.info

data.isnull().sum()

data['Review Text'] .head()

# Downloading and installing necessary NLTK and TextBlob resources
from nltk import download
!pip install textblob
download('stopwords')
# Ensuring 'Review Text' column is of string type
data['Review Text']=data['Review Text'].astype(str)

# Importing additional libraries for text processing
from nltk.corpus import stopwords
from textblob import TextBlob
from textblob import Word

# Converting all text to lowercase
data['Review Text']=data['Review Text'].apply(lambda x:" ".join(x.lower() for x in x.split()))
data['Review Text']=data['Review Text'].str.replace(r'[^\w\s]','')

# Removing stopwords
from nltk.corpus import stopwords
stop=stopwords.words('english')
data['Review Text']=data['Review Text'].apply(lambda x:" ".join(x for x in x.split() if x not in stop))
data['Review Text'].head()

# Correcting spelling
from tqdm import tqdm
from textblob import TextBlob
import nltk
nltk.download('wordnet')

from textblob import TextBlob
def correct_spelling(ReviewText):
  Blob=TextBlob(ReviewText)
  correct_text=Blob.correct()
  return str(correct_text)
tqdm.pandas(desc='correct_spelling')
data['Review Text']=data['Review Text'].progress_apply(correct_spelling)
print(data['Review Text'].head())

# Lemmatizing the words

data['Review Text']=data['Review Text'].apply(lambda x:" ".join(Word(word).lemmatize() for word in x.split()))
data['Review Text'].head()

data['Rating'].shape

sns.countplot(x='Rating',data=data)

Rating=data['Rating'].hist(bins=5)

data['Clothing ID'].count()

# Importing libraries for word cloud and sentiment analysis
from wordcloud import WordCloud
from wordcloud import STOPWORDS

# Analyzing sentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analayzer=SentimentIntensityAnalyzer()
emptyline=[]
for row in tqdm(data['Review Text'],total=len(data),desc='Analyzing Sentiment'):
  vs=analayzer.polarity_scores(row)
  emptyline.append(vs)

data_sentiment=pd.DataFrame(emptyline)
data_sentiment.head()

np.where(data_sentiment['compound']>=0,'positive','negative')

# Assigning sentiment labels

data_sentiment['Sentiment']=np.where(data_sentiment['compound']>=0,'positive','negative')
data_sentiment.head()

data_sentiment['Sentiment'].value_counts()

#Results: Generated sentiment labels (positive/negative) based on sentiment scores

plot=data_sentiment['Sentiment'].value_counts()
plot.plot(kind='bar')